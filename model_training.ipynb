{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"model_training.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMtWyLU3Au0UVVjdeUhbg1Y"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"MKAZfJLBsdyU","colab_type":"text"},"source":["Configuration of the Environment"]},{"cell_type":"code","metadata":{"id":"eemM7gqJsGBU","colab_type":"code","colab":{}},"source":["!kill -9 -1"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"3XeureQisV30","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":51},"outputId":"e78278ab-c471-479f-b49c-60b27de7512a","executionInfo":{"status":"ok","timestamp":1589938143560,"user_tz":-600,"elapsed":3932,"user":{"displayName":"troy cao","photoUrl":"","userId":"07726115307262362470"}}},"source":["import torch\n","\n","torch.cuda.empty_cache()\n","\n","if torch.cuda.is_available():\n","    device = torch.device(\"cuda\")\n","    print(\"There are {} GPUs available.\".format(torch.cuda.device_count()))\n","    print(\"We will use GPU {}\".format(torch.cuda.get_device_name(0)))\n","else:\n","    print(\"There is no GPU available, using the CPU instead!\")\n","    device = torch.device(\"cpu\")"],"execution_count":1,"outputs":[{"output_type":"stream","text":["There are 1 GPUs available.\n","We will use GPU Tesla P100-PCIE-16GB\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"CCB4IPsasHd3","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":258},"outputId":"ebe852c4-e032-4c16-c52b-344ed2a7db66","executionInfo":{"status":"ok","timestamp":1589938162620,"user_tz":-600,"elapsed":16072,"user":{"displayName":"troy cao","photoUrl":"","userId":"07726115307262362470"}}},"source":["!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n","!pip install gputil\n","!pip install psutil\n","!pip install humanize\n","import psutil\n","import humanize\n","import os\n","import GPUtil as GPU\n","GPUs = GPU.getGPUs()\n","# XXX: only one GPU on Colab and isnâ€™t guaranteed\n","gpu = GPUs[0]\n","def printm():\n"," process = psutil.Process(os.getpid())\n"," print(\"Gen RAM Free: \" + humanize.naturalsize( psutil.virtual_memory().available ), \" | Proc size: \" + humanize.naturalsize( process.memory_info().rss))\n"," print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\n","printm()"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Collecting gputil\n","  Downloading https://files.pythonhosted.org/packages/ed/0e/5c61eedde9f6c87713e89d794f01e378cfd9565847d4576fa627d758c554/GPUtil-1.4.0.tar.gz\n","Building wheels for collected packages: gputil\n","  Building wheel for gputil (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for gputil: filename=GPUtil-1.4.0-cp36-none-any.whl size=7413 sha256=75768af385fb6364446f3df586c79dfb7845650b0c37e4ac0b0d94904aca0596\n","  Stored in directory: /root/.cache/pip/wheels/3d/77/07/80562de4bb0786e5ea186911a2c831fdd0018bda69beab71fd\n","Successfully built gputil\n","Installing collected packages: gputil\n","Successfully installed gputil-1.4.0\n","Requirement already satisfied: psutil in /usr/local/lib/python3.6/dist-packages (5.4.8)\n","Requirement already satisfied: humanize in /usr/local/lib/python3.6/dist-packages (0.5.1)\n","Gen RAM Free: 12.7 GB  | Proc size: 280.1 MB\n","GPU RAM Free: 16270MB | Used: 10MB | Util   0% | Total 16280MB\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"ZZqD8J06slQ7","colab_type":"text"},"source":["Now Processing the Data"]},{"cell_type":"code","metadata":{"id":"xnLu19UMC70O","colab_type":"code","outputId":"6dd83033-9bbc-4959-83ef-8f249c53e61b","executionInfo":{"status":"ok","timestamp":1589938747023,"user_tz":-600,"elapsed":10898,"user":{"displayName":"troy cao","photoUrl":"","userId":"07726115307262362470"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["#Changing the 4 to 1\n","import pandas as pd\n","train_with_4 = pd.read_csv('train.csv')\n","train_with_4['target'] = train_with_4['target']/4\n","train_with_4.to_csv('modified_train.csv', index = False)\n","print(\"Transform Complete!\")"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Transform Complete!\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"YgrGs8vpDZzs","colab_type":"code","outputId":"59f2677b-547d-4174-f24f-c1d8e98a2686","executionInfo":{"status":"ok","timestamp":1589938758286,"user_tz":-600,"elapsed":4428,"user":{"displayName":"troy cao","photoUrl":"","userId":"07726115307262362470"}},"colab":{"base_uri":"https://localhost:8080/","height":204}},"source":["#Testing the change\n","import pandas as pd\n","train_with_1 = pd.read_csv('modified_train.csv')\n","train_with_1.head()"],"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Id</th>\n","      <th>date</th>\n","      <th>user</th>\n","      <th>text</th>\n","      <th>target</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>Fri Jun 05 22:04:23 PDT 2009</td>\n","      <td>JGoldsborough</td>\n","      <td>@jbtaylor WIth ya. &amp;quot;I'd like a Palm Pre, ...</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>Sat Jun 06 03:12:21 PDT 2009</td>\n","      <td>Psioui</td>\n","      <td>felt the earthquake this afternoon, it seems t...</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>Sat May 30 19:02:49 PDT 2009</td>\n","      <td>adriville</td>\n","      <td>Ruffles on shirts are like so in, me Likey</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>Thu Jun 25 05:59:18 PDT 2009</td>\n","      <td>Blondie128</td>\n","      <td>Pretty bad night into a crappy morning....FML!...</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>Sat May 30 11:16:35 PDT 2009</td>\n","      <td>khrabrov</td>\n","      <td>@dcbriccetti yeah, what a clear view!</td>\n","      <td>1.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   Id  ... target\n","0   0  ...    1.0\n","1   1  ...    1.0\n","2   2  ...    1.0\n","3   3  ...    0.0\n","4   4  ...    1.0\n","\n","[5 rows x 5 columns]"]},"metadata":{"tags":[]},"execution_count":4}]},{"cell_type":"code","metadata":{"id":"atz_llsjDaBQ","colab_type":"code","colab":{}},"source":["#Defining the generate bigrams method for the Fast_Text class\n","def generate_bigrams(x):\n","    n_grams = set(zip(*[x[i:] for i in range(2)]))\n","    for n_gram in n_grams:\n","        x.append(' '.join(n_gram))\n","    return x"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"hZTzDWoeDaPx","colab_type":"code","colab":{}},"source":["#Getting the relevant imports and the fields for reading training data\n","import torch\n","from torchtext import data\n","from torchtext import datasets\n","import random\n","import pandas as pd\n","import numpy as np\n","\n","SEED = 1234\n","\n","torch.manual_seed(SEED)\n","torch.backends.cudnn.deterministic = True\n","\n","TEXT = data.Field(preprocessing = generate_bigrams)\n","TARGET = data.LabelField(dtype = torch.float)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"33Fk2s82DpfN","colab_type":"code","colab":{}},"source":["#Defining the fields for reading train.csv\n","fields_train = [(None, None), (None, None), (None, None), ('text', TEXT),('target', TARGET)]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"DiK6-ADhmD40","colab_type":"code","colab":{}},"source":["#Reading train.csv\n","train_data = data.TabularDataset(path = 'modified_train.csv',\n","                                 format = 'csv',\n","                                 fields = fields_train,\n","                                 skip_header = True\n",")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"d3Rfc8nZD0U0","colab_type":"code","outputId":"a09e8fac-4c3b-4de0-d7c2-a72362400f16","executionInfo":{"status":"ok","timestamp":1589938814304,"user_tz":-600,"elapsed":952,"user":{"displayName":"troy cao","photoUrl":"","userId":"07726115307262362470"}},"colab":{"base_uri":"https://localhost:8080/","height":54}},"source":["#Testing whether the data was imported successfully\n","print(vars(train_data[0]))"],"execution_count":9,"outputs":[{"output_type":"stream","text":["{'text': ['@jbtaylor', 'WIth', 'ya.', \"&quot;I'd\", 'like', 'a', 'Palm', 'Pre,', 'Touchstone', 'charger.', 'ReadyNow?', 'Yes,', 'that', 'sounds', 'good.', 'But', 'is', 'my', 'beer', 'ready', \"now?'\", '#prelaunch', 'Yes, that', \"ready now?'\", 'charger. ReadyNow?', 'my beer', 'But is', 'good. But', \"&quot;I'd like\", 'Pre, Touchstone', 'Palm Pre,', 'is my', \"now?' #prelaunch\", 'like a', 'ReadyNow? Yes,', 'that sounds', \"ya. &quot;I'd\", 'Touchstone charger.', '@jbtaylor WIth', 'beer ready', 'WIth ya.', 'sounds good.', 'a Palm'], 'target': '1.0'}\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Bfb8DTXFD0fD","colab_type":"code","colab":{}},"source":["#Creating validation set\n","train_data, valid_data = train_data.split(random_state = random.seed(SEED))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"pOmnN2yuD0nt","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":51},"outputId":"13fc4337-4335-4364-8abd-f0e2acdb2c4d","executionInfo":{"status":"ok","timestamp":1589939303533,"user_tz":-600,"elapsed":472342,"user":{"displayName":"troy cao","photoUrl":"","userId":"07726115307262362470"}}},"source":["#Getting the pre-trained word embeddings and building the vocab\n","MAX_VOCAB_SIZE = 25_000\n","\n","TEXT.build_vocab(train_data, \n","                 max_size = MAX_VOCAB_SIZE, \n","                 vectors = \"glove.6B.100d\", \n","                 unk_init = torch.Tensor.normal_)\n","\n","TARGET.build_vocab(train_data)"],"execution_count":11,"outputs":[{"output_type":"stream","text":[".vector_cache/glove.6B.zip: 862MB [06:28, 2.22MB/s]                          \n","100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 399769/400000 [00:21<00:00, 18047.08it/s]"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"AmRgJwqmD0qZ","colab_type":"code","colab":{}},"source":["#defining the batch size and defining the iterators for training and validation data\n","BATCH_SIZE = 64\n","\n","\n","\n","train_iterator = data.Iterator(dataset = train_data, batch_size = BATCH_SIZE,device = device, shuffle = None, train = True, sort_key = lambda x: len(x.text), sort_within_batch = False)\n","valid_iterator = data.Iterator(dataset = valid_data, batch_size = BATCH_SIZE,device = device, shuffle = None, train = False, sort_key = lambda x: len(x.text), sort_within_batch = False)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"arwNTyLvD0tq","colab_type":"code","colab":{}},"source":["#defining the Fast_Text Class\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","class FastText(nn.Module):\n","    def __init__(self, vocab_size, embedding_dim, output_dim, pad_idx):\n","        \n","        super().__init__()\n","        \n","        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=pad_idx)\n","        \n","        self.fc = nn.Linear(embedding_dim, output_dim)\n","        \n","    def forward(self, text):\n","        \n","        #text = [sent len, batch size]\n","        \n","        embedded = self.embedding(text)\n","                \n","        #embedded = [sent len, batch size, emb dim]\n","        \n","        embedded = embedded.permute(1, 0, 2)\n","        \n","        #embedded = [batch size, sent len, emb dim]\n","        \n","        pooled = F.avg_pool2d(embedded, (embedded.shape[1], 1)).squeeze(1) \n","        \n","        #pooled = [batch size, embedding_dim]\n","                \n","        return self.fc(pooled)  \n","        "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"yEQ9h01CD0wf","colab_type":"code","colab":{}},"source":["#defining our models and the relevant parameters\n","INPUT_DIM = len(TEXT.vocab)\n","EMBEDDING_DIM = 100\n","OUTPUT_DIM = 1\n","PAD_IDX = TEXT.vocab.stoi[TEXT.pad_token]\n","\n","model = FastText(INPUT_DIM, EMBEDDING_DIM, OUTPUT_DIM, PAD_IDX)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"nMuq-6L6D0zP","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"923efecb-bffb-4292-a06a-b13b845414e6","executionInfo":{"status":"ok","timestamp":1589939321755,"user_tz":-600,"elapsed":916,"user":{"displayName":"troy cao","photoUrl":"","userId":"07726115307262362470"}}},"source":["def count_parameters(model):\n","    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n","\n","print(f'The model has {count_parameters(model):,} trainable parameters')"],"execution_count":15,"outputs":[{"output_type":"stream","text":["The model has 2,500,301 trainable parameters\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"uF4l6qRiD01u","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":136},"outputId":"a8be099a-c43c-4276-9366-d42b1b2080dd","executionInfo":{"status":"ok","timestamp":1589939324112,"user_tz":-600,"elapsed":780,"user":{"displayName":"troy cao","photoUrl":"","userId":"07726115307262362470"}}},"source":["#Copying the pre-trained vectors to our embedding layers\n","pretrained_embeddings = TEXT.vocab.vectors\n","\n","model.embedding.weight.data.copy_(pretrained_embeddings)"],"execution_count":16,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[-0.1117, -0.4966,  0.1631,  ...,  1.2647, -0.2753, -0.1325],\n","        [-0.8555, -0.7208,  1.3755,  ...,  0.0825, -1.1314,  0.3997],\n","        [-0.1897,  0.0500,  0.1908,  ..., -0.3980,  0.4765, -0.1598],\n","        ...,\n","        [ 0.4849, -0.6371,  0.0804,  ...,  0.5892, -0.1101, -0.2020],\n","        [ 0.0715,  0.3856, -0.5967,  ...,  0.0360,  0.2100, -0.9340],\n","        [ 0.3891,  1.3122, -2.8343,  ..., -0.7519, -1.7957,  1.2788]])"]},"metadata":{"tags":[]},"execution_count":16}]},{"cell_type":"code","metadata":{"id":"Zlx4UQuWomAN","colab_type":"code","colab":{}},"source":["#Zeroing the initial weight of our unknown and padding tokens\n","UNK_IDX = TEXT.vocab.stoi[TEXT.unk_token]\n","\n","model.embedding.weight.data[UNK_IDX] = torch.zeros(EMBEDDING_DIM)\n","model.embedding.weight.data[PAD_IDX] = torch.zeros(EMBEDDING_DIM)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"LrEkw6Q0otMn","colab_type":"code","colab":{}},"source":["#defining our optimizer\n","import torch.optim as optim\n","\n","optimizer = optim.Adam(model.parameters())"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Yt0t_ldkovyq","colab_type":"code","colab":{}},"source":["#defining our loss and porting our model and loss to GPU\n","criterion = nn.BCEWithLogitsLoss()\n","\n","model = model.to(device)\n","criterion = criterion.to(device)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"tcGGUlGVov1s","colab_type":"code","colab":{}},"source":["#defining the accuracy calculation method\n","def binary_accuracy(preds, y):\n","    \"\"\"\n","    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n","    \"\"\"\n","\n","    #round predictions to the closest integer\n","    rounded_preds = torch.round(torch.sigmoid(preds))\n","    correct = (rounded_preds == y).float() #convert into float for division \n","    acc = correct.sum() / len(correct)\n","    return acc"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"iopV0Gmvo63C","colab_type":"code","colab":{}},"source":["#defining the training method\n","def train(model, iterator, optimizer, criterion):\n","    \n","    epoch_loss = 0\n","    epoch_acc = 0\n","    \n","    model.train()\n","    \n","    for batch in iterator:\n","        \n","        optimizer.zero_grad()\n","        \n","        predictions = model(batch.text).squeeze(1)\n","        \n","        loss = criterion(predictions, batch.target)\n","        \n","        acc = binary_accuracy(predictions, batch.target)\n","        \n","        loss.backward()\n","        \n","        optimizer.step()\n","        \n","        epoch_loss += loss.item()\n","        epoch_acc += acc.item()\n","        \n","    return epoch_loss / len(iterator), epoch_acc / len(iterator)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"bzPZ6qFRo_Rc","colab_type":"code","colab":{}},"source":["#defining the validation method\n","def evaluate(model, iterator, criterion):\n","    \n","    epoch_loss = 0\n","    epoch_acc = 0\n","    \n","    model.eval()\n","    \n","    with torch.no_grad():\n","    \n","        for batch in iterator:\n","\n","            predictions = model(batch.text).squeeze(1)\n","            \n","            loss = criterion(predictions, batch.target)\n","            \n","            acc = binary_accuracy(predictions, batch.target)\n","\n","            epoch_loss += loss.item()\n","            epoch_acc += acc.item()\n","        \n","    return epoch_loss / len(iterator), epoch_acc / len(iterator)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"AvC7OaibpCRf","colab_type":"code","colab":{}},"source":["#defining the method to calculate epoch time\n","import time\n","\n","def epoch_time(start_time, end_time):\n","    elapsed_time = end_time - start_time\n","    elapsed_mins = int(elapsed_time / 60)\n","    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n","    return elapsed_mins, elapsed_secs"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"_9t47laBpGSi","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":527},"outputId":"39bdad6b-980e-4136-cad6-07f3b7818339","executionInfo":{"status":"ok","timestamp":1589940012102,"user_tz":-600,"elapsed":647138,"user":{"displayName":"troy cao","photoUrl":"","userId":"07726115307262362470"}}},"source":["#TRAINING!\n","N_EPOCHS = 10\n","\n","best_valid_loss = float('inf')\n","\n","for epoch in range(N_EPOCHS):\n","\n","    start_time = time.time()\n","    \n","    train_loss, train_acc = train(model, train_iterator, optimizer, criterion)\n","    valid_loss, valid_acc = evaluate(model, valid_iterator, criterion)\n","    \n","    end_time = time.time()\n","\n","    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n","    \n","    if valid_loss < best_valid_loss:\n","        best_valid_loss = valid_loss\n","        torch.save(model.state_dict(), 'tut3-model.pt')\n","    \n","    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n","    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n","    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')"],"execution_count":24,"outputs":[{"output_type":"stream","text":["Epoch: 01 | Epoch Time: 1m 8s\n","\tTrain Loss: 0.485 | Train Acc: 77.71%\n","\t Val. Loss: 0.571 |  Val. Acc: 79.80%\n","Epoch: 02 | Epoch Time: 1m 4s\n","\tTrain Loss: 0.442 | Train Acc: 80.37%\n","\t Val. Loss: 0.596 |  Val. Acc: 79.66%\n","Epoch: 03 | Epoch Time: 1m 4s\n","\tTrain Loss: 0.437 | Train Acc: 80.68%\n","\t Val. Loss: 0.593 |  Val. Acc: 79.86%\n","Epoch: 04 | Epoch Time: 1m 3s\n","\tTrain Loss: 0.435 | Train Acc: 80.76%\n","\t Val. Loss: 0.588 |  Val. Acc: 79.94%\n","Epoch: 05 | Epoch Time: 1m 4s\n","\tTrain Loss: 0.434 | Train Acc: 80.85%\n","\t Val. Loss: 0.590 |  Val. Acc: 79.88%\n","Epoch: 06 | Epoch Time: 1m 4s\n","\tTrain Loss: 0.433 | Train Acc: 80.90%\n","\t Val. Loss: 0.588 |  Val. Acc: 79.88%\n","Epoch: 07 | Epoch Time: 1m 4s\n","\tTrain Loss: 0.432 | Train Acc: 80.93%\n","\t Val. Loss: 0.598 |  Val. Acc: 79.89%\n","Epoch: 08 | Epoch Time: 1m 4s\n","\tTrain Loss: 0.432 | Train Acc: 81.01%\n","\t Val. Loss: 0.595 |  Val. Acc: 79.93%\n","Epoch: 09 | Epoch Time: 1m 3s\n","\tTrain Loss: 0.431 | Train Acc: 81.03%\n","\t Val. Loss: 0.591 |  Val. Acc: 79.92%\n","Epoch: 10 | Epoch Time: 1m 4s\n","\tTrain Loss: 0.431 | Train Acc: 81.06%\n","\t Val. Loss: 0.602 |  Val. Acc: 79.87%\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"eHzdEVo-4fY6","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"eOlVxGsl4fvm","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}